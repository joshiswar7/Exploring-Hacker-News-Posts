{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "Hacker News is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "What is interesting is that here we would be interested in focussing on posts where the titles begin with either `'Ask HN'` or `'Show HN'`. Users Use `Ask HN` to ask the Hacker News community a specific question.\n",
    "\n",
    "\n",
    "Examples\n",
    "\n",
    "\n",
    "_`Ask HN: How to improve my personal website?\n",
    "Ask HN: Am I the only one outraged by Twitter shutting down share counts?`_\n",
    "\n",
    "\n",
    "Similarly, users use `Show HN` to show the Hacker News community a project, product, or just generally something interesting.\n",
    "\n",
    "\n",
    "Examples\n",
    "\n",
    "\n",
    "_`Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform'\n",
    "Show HN: Something pointless I made`_\n",
    "\n",
    "\n",
    "Now we would aim at comparing these two types of posts and explore:\n",
    "1. Do `Ask HN` or `Show HM` receive more comments on average?\n",
    "2. Do posts created at a certsain time receive more comments on average?\n",
    "\n",
    "**Data Source**\n",
    "\n",
    "The data set being used in this project is from the Kaggle, however it has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions.\n",
    "\n",
    "Below are descriptions of the columns:\n",
    "\n",
    "`id`: The unique identifier from Hacker News for the post\n",
    "\n",
    "`title`: The title of the post\n",
    "\n",
    "`url`: The URL that the posts links to, if it the post has a URL\n",
    "\n",
    "`num_points`: The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "\n",
    "`num_comments`: The number of comments that were made on the post\n",
    "\n",
    "`author`: The username of the person who submitted the post\n",
    "\n",
    "`created_at`: The date and time at which the post was submitted\n",
    "\n",
    "\n",
    "\n",
    "Let us start off by importing our data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20100\n",
      "\n",
      "\n",
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "\n",
    "print(len(hn))\n",
    "print('\\n')\n",
    "print(headers)\n",
    "print('\\n')\n",
    "print(hn[:4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtering our Data**\n",
    "\n",
    "As discussed, we want to isolate the posts with `Ask HN` and `Show HN`. Let us create two seperate list of lists to contain the data for these titles.\n",
    "\n",
    "To find the posts which begin with either `Ask HN` or `Show HN`, we'll use the string method `startswith`. Let us do a test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "string1 = \"SwarJoshi\"\n",
    "print(string1.startswith(\"Swar\"))\n",
    "print(string1.startswith(\"swar\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this approach works, it shows the importance of case sensitivity. As we can not control the posts, we would have to cater our approach to control this case of case sensitivity. \n",
    "\n",
    "So, we will convert all the strings into a lower case user `lower()` and then use our isolation methods on the stirings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    title = title.lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "        \n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can make the following basic assumptions:\n",
    "1. There are more number of `Ask HN`(1744) posts as compared to `Show HN`(1162) posts\n",
    "2. Neither of those constitute more than 10% of the data set individually. \n",
    "\n",
    "Digging deeper, let us determine if ask posts or show posts receive more comments on average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.038417431192661\n",
      "10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "for row in ask_posts:\n",
    "    comments = int(row[4])\n",
    "    total_ask_comments += comments\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print(avg_ask_comments)\n",
    "\n",
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    comments = int(row[4])\n",
    "    total_show_comments += comments    \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print(avg_show_comments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, `Ask HN` as 14 comments on average on each post while `Show HN` has 10 comments on average. \n",
    "This comes in addition to the fact that there are more `Ask HN` posts in general as compared to `Show HN` posts. \n",
    "\n",
    "With a higher number of posts and more comments, it could be said that `Ask HN` posts have higher engagement in comparison with `Show HN` posts.\n",
    "\n",
    "The reason behind this could also be the fact that, when a person asks a question it is directly requesting a response. In general, seeking a response would ideally be met with a few comments and replies from the original poster leader to increased number of comments.\n",
    "\n",
    "As we see that ask posts recceive more comments, we would now focus the rest of our analysis just on these posts.\n",
    "\n",
    "**Bringing Time of Posting into the Picture**\n",
    "\n",
    "It is no secret, that all digital marketers and social media 'influencers' on Facebook, Twitter, Instagram etc. have a set time for posting their regular images (not the I-wish-it-were-occassional drunk ramblings) which brings in the most engagement and views for them. While the users/posters of HN are way cooler in general, we could possibly look into the possibility of possible times when the post engagement is higher. \n",
    "\n",
    "In order to perform this analysis we will:\n",
    "1. Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "2. Calculate the average number of comments ask posts receive by hour created.\n",
    "\n",
    "The Module that we will use will be `datetime` module which we will use in the `created_at` column (Index 6) Moreover, we use `strptime()` to bring the date and time in the column to our desired format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 55, 1: 60, 2: 58, 3: 54, 4: 47, 5: 46, 6: 44, 7: 34, 8: 48, 9: 45, 10: 59, 11: 58, 12: 73, 13: 85, 14: 107, 15: 116, 16: 108, 17: 100, 18: 109, 19: 110, 20: 80, 21: 109, 22: 71, 23: 68}\n",
      "\n",
      "\n",
      "{0: 447, 1: 683, 2: 1381, 3: 421, 4: 337, 5: 464, 6: 397, 7: 267, 8: 492, 9: 251, 10: 793, 11: 641, 12: 687, 13: 1253, 14: 1416, 15: 4477, 16: 1814, 17: 1146, 18: 1439, 19: 1188, 20: 1722, 21: 1745, 22: 479, 23: 543}\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "for row in ask_posts:\n",
    "    created = row[6]\n",
    "    comments = int(row[4])\n",
    "    new1 = [created, comments]\n",
    "    result_list.append(new1)\n",
    "\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    thehour = row[0]\n",
    "    comment = row[1]\n",
    "    dt_object = dt.datetime.strptime(thehour, \"%m/%d/%Y %H:%M\")\n",
    "    hour = dt_object.hour\n",
    "    if hour in counts_by_hour:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comment\n",
    "    else:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comment\n",
    "        \n",
    "print(counts_by_hour)\n",
    "print('\\n')\n",
    "print(comments_by_hour)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`counts_by_hour` - Shows total posts within that hour\n",
    "`comments_by_hour`- Shows total comments within that hour \n",
    "\n",
    "This has given us a total count & how many comments we have had in total during the course of the day within `Ask HN` posts. Let us find out the average comments per hour for the same. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 8.127272727272727], [1, 11.383333333333333], [2, 23.810344827586206], [3, 7.796296296296297], [4, 7.170212765957447], [5, 10.08695652173913], [6, 9.022727272727273], [7, 7.852941176470588], [8, 10.25], [9, 5.5777777777777775], [10, 13.440677966101696], [11, 11.051724137931034], [12, 9.41095890410959], [13, 14.741176470588234], [14, 13.233644859813085], [15, 38.5948275862069], [16, 16.796296296296298], [17, 11.46], [18, 13.20183486238532], [19, 10.8], [20, 21.525], [21, 16.009174311926607], [22, 6.746478873239437], [23, 7.985294117647059]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for row in comments_by_hour:\n",
    "    average = (comments_by_hour[row]/counts_by_hour[row])\n",
    "    new1 = [row, average]\n",
    "    avg_by_hour.append(new1)\n",
    "    \n",
    "print(avg_by_hour)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments : [[38.5948275862069, 15], [23.810344827586206, 2], [21.525, 20], [16.796296296296298, 16]]\n",
      "\n",
      "\n",
      "15:00 : 38.5948275862069 average comments per post\n",
      "\n",
      "\n",
      "02:00 : 23.810344827586206 average comments per post\n",
      "\n",
      "\n",
      "20:00 : 21.525 average comments per post\n",
      "\n",
      "\n",
      "16:00 : 16.796296296296298 average comments per post\n",
      "\n",
      "\n",
      "21:00 : 16.009174311926607 average comments per post\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    temp = row[0]\n",
    "    temp1 = row[1]\n",
    "    swap_avg_by_hour.append([temp1, temp])\n",
    "    \n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "\n",
    "print(\"Top 5 Hours for Ask Posts Comments :\",sorted_swap[:4])\n",
    "print('\\n')\n",
    "\n",
    "for average, hour in sorted_swap[:5]:\n",
    "    dt_hour = dt.datetime.strptime(str(hour), \"%H\")\n",
    "    dt_hour = dt_hour.strftime(\"%H:%M\")\n",
    "\n",
    "    print(\"{} : {} average comments per post\".format(dt_hour,average))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that post in the hour between 15:00 and 16:00 EST have the highest comments in the `Ask HN` section. \n",
    "\n",
    "This could be possibly due to eitherdue to the following reasons:\n",
    "1. General break time at workplace for tech folks working in USA and Canada. or\n",
    "2. More inflow of comments could be from European countries (CET) where it is then 20:00 and later on during the day for people there.\n",
    "\n",
    "This is followed by the hour between 02:00 and 03:00. \n",
    "\n",
    "Considering that 'Hacker News' is primarily an American company, 02:00 seems rather odd, however the contributers are not necessarily from the US and the 02:00 post comments are probably from either the noctornal American techies (or their Silicon Valley buddies who left late from work, their non-noctornal South-Asian counterparts or early bird techies from Europe/Africa.\n",
    "\n",
    "To ensure most amount of replies, the posts should be made between 15:00 and 16:00 (even a little later woiuld not hurt as the hour between 16:00 and 17:00 has also made the list but doesnt look all that impressive)\n",
    "\n",
    "But these are relevant to people living in EST, what if I want to figure our what my chances are as a person living in Germany?\n",
    "\n",
    "Let's add the 5 hours to convert it from EST to CET using `dt.timedelta()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:00 : 38.5948275862069 average comments per post\n",
      "\n",
      "\n",
      "07:00 : 23.810344827586206 average comments per post\n",
      "\n",
      "\n",
      "01:00 : 21.525 average comments per post\n",
      "\n",
      "\n",
      "21:00 : 16.796296296296298 average comments per post\n",
      "\n",
      "\n",
      "02:00 : 16.009174311926607 average comments per post\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for average, hour in sorted_swap[:5]:\n",
    "    dt_hour = dt.datetime.strptime(str(hour), \"%H\")\n",
    "    dt_hour = dt_hour + dt.timedelta(hours=5)\n",
    "    dt_hour = dt_hour.strftime(\"%H:%M\")\n",
    "    \n",
    "    print(\"{} : {} average comments per post\".format(dt_hour,average))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There! As someone living in Germany, my best chances of getting the most amount of engagement is if I post between 20:00 and 21:00 CET (as I mentioned a little later is fine too, but not optimal), or if I post between 07:00 and 08:00. This is subject to ofcourse, if I have something valuable to ask in my `Ask HN` post. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
